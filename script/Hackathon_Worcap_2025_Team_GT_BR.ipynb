{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IzadoraSC/hackathon_workcap_2025/blob/main/Hackathon_Worcap_2025_Team_GT_BR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HACKATHON - WORCAP - 2025\n",
        "\n",
        "---\n",
        "Team: GT-BR\n",
        "\n",
        "Integrantes: Alejandro Lopez, Izadora S. de Carvalho, Joaquim AJR\n",
        "\n",
        "Capitão: Alejandro Lopez\n",
        "\n",
        "Repositório do Projeto: [GitHub](https://github.com/IzadoraSC/hackathon_workcap_2025)\n",
        "\n",
        "Kaggle: [Hackaton WorCap 2025](https://www.kaggle.com/competitions/worcap-2025)"
      ],
      "metadata": {
        "id": "h1OCeF7RqSd2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSiT9DHUidDK"
      },
      "source": [
        "#U-Net Siamesa com módulos de atenção scSE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOUL2thijClm"
      },
      "source": [
        "O objetivo principal deste notebook é implementar uma rede neural U-Net do tipo siamesa com módulos de atenção, a fim de focar tanto nas regiões corretas (espaço) quanto nas características corretas (canais), o que, segundo Murari et al. (2023), mostra-se especialmente útil em tarefas de segmentação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZdRtv2t7-5_"
      },
      "source": [
        "#Instalar pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mmTeOK2ahi",
        "outputId": "41acc422-aaf7-4fed-f1bf-55b50a0cc4dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.8.3)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.2.1)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.3)\n",
            "Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rasterio -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIr40K6e75-m"
      },
      "source": [
        "#Importar pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrsOw3GJ2Clw",
        "outputId": "bad4cf8e-24cd-485c-bae3-0bf0e08d4693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os, random, math, csv\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import rasterio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.padding import ReplicationPad2d\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from contextlib import ExitStack\n",
        "import pandas as pd\n",
        "\n",
        "# Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogbv8ARr7yxP"
      },
      "source": [
        "#Data Loader\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ecQ0ixB88qG"
      },
      "source": [
        "## Reprodutibilidade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g-klDWU8-1I",
        "outputId": "887e6a25-cde8-4b40-e8a7-95b939c6a892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# Reprodutibilidade e cuDNN\n",
        "# -------------------------\n",
        "\n",
        "#Definimos uma função set_seed para fixar a seed aleatória (padrão 42).\n",
        "#Isso garante que operações que envolvem aleatoriedade (embaralhar dataset, inicializar pesos, augmentações, etc.) sejam reprodutíveis entre execuções.\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True  # Ativa um otimizador interno do cuDNN (biblioteca da NVIDIA usada pelo PyTorch para convoluções). Acelera convs para shapes fixos.\n",
        "\n",
        "\n",
        "#As duas linhas abaixo definem se o treinamento será feito na GPU (cuda) ou na CPU, dependendo do que está disponível e imprimem o dispositivo.\n",
        "\n",
        "#Em seguida, imprime o dispositivo escolhido.\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXUMH24q93Su"
      },
      "source": [
        "## Dataset bitemporal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZMQwfwm93dN"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Dataset bitemporal (T1, T2, máscara 0/1)\n",
        "#Garantimos que cada par de imagens esteja alinhado com sua máscara e pronto para ser passado ao modelo.\n",
        "# =========================\n",
        "class SiameseDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Espera nomes 'recorte_*.tif' em T10_dir, T20_dir e mask_dir.\n",
        "    Lê todas as bandas (C,H,W), normaliza cada tile para [0,1] via min-max local,\n",
        "    e retorna tensores float32: t1, t2, mask(1,H,W).\n",
        "\n",
        "    Se 'ids' for fornecido, usa apenas esses IDs; caso contrário, usa todos os IDs comuns.\n",
        "    \"\"\"\n",
        "    def __init__(self, T10_dir, T20_dir, mask_dir, transform=None, ids=None):   # possui a responsabilidade de criar o objeto da classe SiameseDataset. Nela será contida todas as informações principais do objeto.\n",
        "        self.T10_dir  = str(T10_dir)    #garantimos que os caminhos são string\n",
        "        self.T20_dir  = str(T20_dir)\n",
        "        self.mask_dir = str(mask_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "        def recortes(d):    #Lista todos os arquivos .tif começando com recorte_. Retorna um conjunto {…} de nomes. Além disso, calculamos intersecção entre os nomes das trÊs pastas.\n",
        "\n",
        "            return {n for n in os.listdir(d) if n.startswith(\"recorte_\") and n.endswith(\".tif\")}\n",
        "        common = recortes(self.T10_dir) & recortes(self.T20_dir) & recortes(self.mask_dir)\n",
        "        if not common:\n",
        "            raise RuntimeError(\"Nenhum 'recorte_*.tif' comum encontrado nos três diretórios.\")\n",
        "\n",
        "\n",
        "        ids_all = sorted([n.split('_', 1)[1].replace('.tif', '') for n in common])   #Extrai só o ID de cada arquivo (ex: recorte_123.tif → 123).Ordena em ordem crescente.\n",
        "        if ids is None:\n",
        "            self.ids = ids_all\n",
        "        else:\n",
        "            ids = set(ids)\n",
        "            missing = ids - set(ids_all)\n",
        "            if missing:\n",
        "                raise ValueError(f\"IDs não encontrados nos diretórios: {sorted(list(missing))[:5]} ...\")\n",
        "            self.ids = sorted(list(ids))\n",
        "\n",
        "    def __len__(self):    #Retorna o número de amostras.\n",
        "        return len(self.ids)\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _read_image(path):    #Lê todas as bandas em formato (C, H, W). Retorna tensor torch.float32.\n",
        "        with rasterio.open(path) as src:\n",
        "            img = src.read().astype(np.float32)  # (C,H,W)\n",
        "            img = np.nan_to_num(img, nan=0.0)     # Substitui NaN por 0.0. Normaliza min-max para [0, 1] por tile\n",
        "            mn, mx = img.min(), img.max()\n",
        "            if mx > mn:\n",
        "                img = (img - mn) / (mx - mn)\n",
        "            else:\n",
        "                img = np.zeros_like(img, dtype=np.float32)   #Se todos os valores forem iguais, gera um array de zeros.\n",
        "        return torch.from_numpy(img)  # (C,H,W) float32\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _read_mask(path):  #Lê a mascara.\n",
        "        with rasterio.open(path) as src:\n",
        "            m = src.read(1).astype(np.float32)  # (H,W)\n",
        "            m = np.nan_to_num(m, nan=0.0)      # Substitui NaN por 0.0.\n",
        "            m = (m > 0).astype(np.float32)      #mascara binaria False=0, True=1\n",
        "        return torch.from_numpy(m).unsqueeze(0)  # (1,H,W)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):  #Recupera o ID pelo índice.\n",
        "        id_ = self.ids[idx]\n",
        "        fname = f\"recorte_{id_}.tif\" #Monta o nome do arquivo.\n",
        "        t1 = self._read_image(os.path.join(self.T10_dir,  fname))    #Lê t1, t2 e mask.\n",
        "        t2 = self._read_image(os.path.join(self.T20_dir,  fname))\n",
        "        m  = self._read_mask (os.path.join(self.mask_dir, fname))\n",
        "\n",
        "        if self.transform is not None:      #Se houver transformações (JointAugment, por exemplo), aplica de forma sincronizada.\n",
        "            t1, t2, m = self.transform(t1, t2, m)\n",
        "\n",
        "        return t1, t2, m  #Retorna um triplo: (t1, t2, mask)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx-cImwoOkQI"
      },
      "source": [
        "##Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaL2_N5fOtwZ"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Augment conjunto (sincronizado)\n",
        "# =========================\n",
        "\n",
        "#A ideia é aumentar a variabilidade do dataset para que o modelo não fique “decorando” posições fixas.\n",
        "\n",
        "#Como trabalhamos com pares de imagens (antes e depois) + máscara, é essencial que a mesma transformação seja aplicada aos três ao mesmo tempo, mantendo alinhamento pixel a pixel.\n",
        "\n",
        "class JointAugment:\n",
        "    \"\"\"Flips e rotações de 90° sincronizadas para t1, t2, mask.\"\"\"\n",
        "    def __call__(self, t1, t2, mask):\n",
        "        # flip H\n",
        "        if torch.rand(1).item() < 0.5:\n",
        "            t1 = t1.flip(-1); t2 = t2.flip(-1); mask = mask.flip(-1)    #espelhamento horizontal aplicado em t1, t2 e mask\n",
        "        # flip V\n",
        "        if torch.rand(1).item() < 0.5:\n",
        "            t1 = t1.flip(-2); t2 = t2.flip(-2); mask = mask.flip(-2)   # espelhamento vertical\n",
        "\n",
        "\n",
        "        # geramos um número aleatorio de 0 a 3, sendo que cada numero representa a rotação (0/90/180/270) que será aplicada no dataset\n",
        "        k = torch.randint(0, 4, (1,)).item()\n",
        "        if k > 0:\n",
        "            t1 = torch.rot90(t1, k, dims=(-2, -1))\n",
        "            t2 = torch.rot90(t2, k, dims=(-2, -1))\n",
        "            mask = torch.rot90(mask, k, dims=(-2, -1))\n",
        "        return t1, t2, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdJa0Zx2j60L"
      },
      "source": [
        "#Construção do módulo de atenção"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAYGM055j14l"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# ATENÇÃO scSE (cSE + sSE)\n",
        "#Concurrent Spatial and Channel 'Squeeze & Excitation' (Compactação e Excitação Espacial e de Canais Concorrentes)\n",
        "# =========================\n",
        "\n",
        "# Este módulo de atenção, Segundo Ngoc et al. (2024), melhoram a precisão ao concentrar-se em áreas ricas em informação, em vez de processar a imagem inteira.\n",
        "\n",
        "# A combinação dos modulos cSE e sSE potencializa a capacidade de modulação de características do bloco, recalibrando de forma eficaz tanto a informação espacial quanto a de canais dentro da rede.\n",
        "\n",
        "\n",
        "#O cSE responde “o que olhar?” (features/canais).\n",
        "\n",
        "\n",
        "class cSE(nn.Module):\n",
        "    \"\"\"Channel Squeeze & Excitation.\"\"\"\n",
        "    def __init__(self, c, r=8):\n",
        "        super().__init__()\n",
        "        c_mid = max(c // r, 1)\n",
        "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc1 = nn.Conv2d(c, c_mid, 1, bias=True)\n",
        "        self.fc2 = nn.Conv2d(c_mid, c, 1, bias=True)\n",
        "    def forward(self, x):\n",
        "        w = self.avg(x)\n",
        "        w = F.relu(self.fc1(w), inplace=True)\n",
        "        w = torch.sigmoid(self.fc2(w))\n",
        "        return x * w\n",
        "\n",
        "\n",
        "#O sSE responde “onde olhar?” (posições na imagem).\n",
        "\n",
        "\n",
        "\n",
        "class sSE(nn.Module):\n",
        "    \"\"\"Spatial Squeeze & Excitation.\"\"\"\n",
        "    def __init__(self, c):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(c, 1, kernel_size=1, bias=True)\n",
        "    def forward(self, x):\n",
        "        w = torch.sigmoid(self.conv(x))\n",
        "        return x * w\n",
        "\n",
        "\n",
        "#O scSE junta os dois para responder: “quais canais são importantes e em quais posições eles importam mais?”\n",
        "\n",
        "\n",
        "class scSE(nn.Module):\n",
        "    \"\"\"Concurrent Spatial & Channel SE (soma das atenções).\"\"\"\n",
        "    def __init__(self, c, r=8):\n",
        "        super().__init__()\n",
        "        self.cse = cSE(c, r=r)\n",
        "        self.sse = sSE(c)\n",
        "    def forward(self, x):\n",
        "        return self.cse(x) + self.sse(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdwVJ2oxTqle"
      },
      "source": [
        "#Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeXOZOf_Tqt0"
      },
      "source": [
        "##SiamUnet Diff + scSE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Modelo: SiamUnet_diff + scSE\n",
        "# =========================\n",
        "\n",
        "class SiamUnet_diff(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes=1, enable_attention=True, attn_reduction=8):\n",
        "        super(SiamUnet_diff, self).__init__()\n",
        "        self.enable_attention = enable_attention\n",
        "\n",
        "        # --------------------------\n",
        "        # ENCODER (compartilhado)\n",
        "        # Cada \"stage\" dobra canais e reduz H,W pela metade via max-pool.\n",
        "        # Dropout2d leve em cada bloco para regularizar.\n",
        "        # --------------------------\n",
        "\n",
        "        # Encoder (compartilhado)\n",
        "        self.conv11 = nn.Conv2d(n_channels, 16, kernel_size=3, padding=1)\n",
        "        self.bn11 = nn.BatchNorm2d(16); self.do11 = nn.Dropout2d(p=0.2)\n",
        "        self.conv12 = nn.Conv2d(16, 16, kernel_size=3, padding=1)\n",
        "        self.bn12 = nn.BatchNorm2d(16); self.do12 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.bn21 = nn.BatchNorm2d(32); self.do21 = nn.Dropout2d(p=0.2)\n",
        "        self.conv22 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.bn22 = nn.BatchNorm2d(32); self.do22 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv31 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn31 = nn.BatchNorm2d(64); self.do31 = nn.Dropout2d(p=0.2)\n",
        "        self.conv32 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn32 = nn.BatchNorm2d(64); self.do32 = nn.Dropout2d(p=0.2)\n",
        "        self.conv33 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn33 = nn.BatchNorm2d(64); self.do33 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.conv41 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn41 = nn.BatchNorm2d(128); self.do41 = nn.Dropout2d(p=0.2)\n",
        "        self.conv42 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn42 = nn.BatchNorm2d(128); self.do42 = nn.Dropout2d(p=0.2)\n",
        "        self.conv43 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn43 = nn.BatchNorm2d(128); self.do43 = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        # --------------------------\n",
        "        # Atenção scSE por escala e por tempo\n",
        "        # (assume classe scSE(channels, r) definida na celda acima\n",
        "        # Se desativado, usa nn.Identity() para custo zero.\n",
        "        # --------------------------\n",
        "\n",
        "        # scSE em cada escala\n",
        "        if enable_attention:\n",
        "            self.att1_T1 = scSE(16, r=attn_reduction)\n",
        "            self.att1_T2 = scSE(16, r=attn_reduction)\n",
        "            self.att2_T1 = scSE(32, r=attn_reduction)\n",
        "            self.att2_T2 = scSE(32, r=attn_reduction)\n",
        "            self.att3_T1 = scSE(64, r=attn_reduction)\n",
        "            self.att3_T2 = scSE(64, r=attn_reduction)\n",
        "            self.att4_T1 = scSE(128, r=attn_reduction)\n",
        "            self.att4_T2 = scSE(128, r=attn_reduction)\n",
        "        else:\n",
        "            self.att1_T1 = nn.Identity(); self.att1_T2 = nn.Identity()\n",
        "            self.att2_T1 = nn.Identity(); self.att2_T2 = nn.Identity()\n",
        "            self.att3_T1 = nn.Identity(); self.att3_T2 = nn.Identity()\n",
        "            self.att4_T1 = nn.Identity(); self.att4_T2 = nn.Identity()\n",
        "\n",
        "\n",
        "        # --------------------------\n",
        "        # DECODER\n",
        "        # Estratégia:\n",
        "        # (i) upsample com ConvTranspose2d (stride=2 nos \"upconv*\"),\n",
        "        # (ii) pad para igualar a dimensão da \"skip\",\n",
        "        # (iii) concatenação com |skip_T1 - skip_T2|,\n",
        "        # (iv) \"conv transpose\" com stride=1 (atua como conv 3x3) + BN + ReLU + Dropout.\n",
        "        # --------------------------\n",
        "\n",
        "        # Decoder\n",
        "        self.upconv4 = nn.ConvTranspose2d(128, 128, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "        self.conv43d = nn.ConvTranspose2d(256, 128, kernel_size=3, padding=1)\n",
        "        self.bn43d = nn.BatchNorm2d(128); self.do43d = nn.Dropout2d(p=0.2)\n",
        "        self.conv42d = nn.ConvTranspose2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn42d = nn.BatchNorm2d(128); self.do42d = nn.Dropout2d(p=0.2)\n",
        "        self.conv41d = nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.bn41d = nn.BatchNorm2d(64); self.do41d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose2d(64, 64, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "        self.conv33d = nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.bn33d = nn.BatchNorm2d(64); self.do33d = nn.Dropout2d(p=0.2)\n",
        "        self.conv32d = nn.ConvTranspose2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn32d = nn.BatchNorm2d(64); self.do32d = nn.Dropout2d(p=0.2)\n",
        "        self.conv31d = nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1)\n",
        "        self.bn31d = nn.BatchNorm2d(32); self.do31d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(32, 32, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "        self.conv22d = nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1)\n",
        "        self.bn22d = nn.BatchNorm2d(32); self.do22d = nn.Dropout2d(p=0.2)\n",
        "        self.conv21d = nn.ConvTranspose2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.bn21d = nn.BatchNorm2d(16); self.do21d = nn.Dropout2d(p=0.2)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose2d(16, 16, kernel_size=3, padding=1, stride=2, output_padding=1)\n",
        "        self.conv12d = nn.ConvTranspose2d(32, 16, kernel_size=3, padding=1)\n",
        "        self.bn12d = nn.BatchNorm2d(16); self.do12d = nn.Dropout2d(p=0.2)\n",
        "        self.conv11d = nn.ConvTranspose2d(16, n_classes, kernel_size=3, padding=1)  # n_classes=1\n",
        "\n",
        "    def _encode_once(self, x):\n",
        "\n",
        "        \"\"\"Passa uma imagem (T1 ou T2) por um encoder.\n",
        "        Retorna features por escala + o \"bottleneck\" depois do último pool.\n",
        "        \"\"\"\n",
        "        # Stage 1 (C=16, H/2)\n",
        "        x11 = self.do11(F.relu(self.bn11(self.conv11(x))))\n",
        "        x12 = self.do12(F.relu(self.bn12(self.conv12(x11))))\n",
        "        x1p = F.max_pool2d(x12, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 2 (C=32, H/4)\n",
        "        x21 = self.do21(F.relu(self.bn21(self.conv21(x1p))))\n",
        "        x22 = self.do22(F.relu(self.bn22(self.conv22(x21))))\n",
        "        x2p = F.max_pool2d(x22, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 3 (C=64, H/8)\n",
        "        x31 = self.do31(F.relu(self.bn31(self.conv31(x2p))))\n",
        "        x32 = self.do32(F.relu(self.bn32(self.conv32(x31))))\n",
        "        x33 = self.do33(F.relu(self.bn33(self.conv33(x32))))\n",
        "        x3p = F.max_pool2d(x33, kernel_size=2, stride=2)\n",
        "\n",
        "        # Stage 4 (C=128, H/16)\n",
        "        x41 = self.do41(F.relu(self.bn41(self.conv41(x3p))))\n",
        "        x42 = self.do42(F.relu(self.bn42(self.conv42(x41))))\n",
        "        x43 = self.do43(F.relu(self.bn43(self.conv43(x42))))\n",
        "        x4p = F.max_pool2d(x43, kernel_size=2, stride=2)\n",
        "        return (x12, x22, x33, x43, x4p)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "\n",
        "        # --------------------------\n",
        "        # Encoders siameses (mesmos pesos)\n",
        "        # --------------------------\n",
        "\n",
        "        # Encoders (pesos compartilhados)\n",
        "        x12_1, x22_1, x33_1, x43_1, _    = self._encode_once(x1)\n",
        "        x12_2, x22_2, x33_2, x43_2, x4p  = self._encode_once(x2)\n",
        "\n",
        "        # Aplicar scSE antes de calcular diferenças\n",
        "        if self.enable_attention:\n",
        "            x12_1 = self.att1_T1(x12_1); x12_2 = self.att1_T2(x12_2)\n",
        "            x22_1 = self.att2_T1(x22_1); x22_2 = self.att2_T2(x22_2)\n",
        "            x33_1 = self.att3_T1(x33_1); x33_2 = self.att3_T2(x33_2)\n",
        "            x43_1 = self.att4_T1(x43_1); x43_2 = self.att4_T2(x43_2)\n",
        "\n",
        "        # Decoder 4d\n",
        "        x4d = self.upconv4(x4p)\n",
        "        pad4 = nn.ReplicationPad2d((0, x43_1.size(3) - x4d.size(3), 0, x43_1.size(2) - x4d.size(2)))\n",
        "        x4d = torch.cat((pad4(x4d), torch.abs(x43_1 - x43_2)), 1)  # 256\n",
        "        x43d = self.do43d(F.relu(self.bn43d(self.conv43d(x4d))))\n",
        "        x42d = self.do42d(F.relu(self.bn42d(self.conv42d(x43d))))\n",
        "        x41d = self.do41d(F.relu(self.bn41d(self.conv41d(x42d))))\n",
        "\n",
        "        # Decoder 3d\n",
        "        x3d = self.upconv3(x41d)\n",
        "        pad3 = nn.ReplicationPad2d((0, x33_1.size(3) - x3d.size(3), 0, x33_1.size(2) - x3d.size(2)))\n",
        "        x3d = torch.cat((pad3(x3d), torch.abs(x33_1 - x33_2)), 1)  # 128\n",
        "        x33d = self.do33d(F.relu(self.bn33d(self.conv33d(x3d))))\n",
        "        x32d = self.do32d(F.relu(self.bn32d(self.conv32d(x33d))))\n",
        "        x31d = self.do31d(F.relu(self.bn31d(self.conv31d(x32d))))\n",
        "\n",
        "        # Decoder 2d\n",
        "        x2d = self.upconv2(x31d)\n",
        "        pad2 = nn.ReplicationPad2d((0, x22_1.size(3) - x2d.size(3), 0, x22_1.size(2) - x2d.size(2)))\n",
        "        x2d = torch.cat((pad2(x2d), torch.abs(x22_1 - x22_2)), 1)  # 64\n",
        "        x22d = self.do22d(F.relu(self.bn22d(self.conv22d(x2d))))\n",
        "        x21d = self.do21d(F.relu(self.bn21d(self.conv21d(x22d))))\n",
        "\n",
        "        # Decoder 1d\n",
        "        x1d = self.upconv1(x21d)\n",
        "        pad1 = nn.ReplicationPad2d((0, x12_1.size(3) - x1d.size(3), 0, x12_1.size(2) - x1d.size(2)))\n",
        "        x1d = torch.cat((pad1(x1d), torch.abs(x12_1 - x12_2)), 1)  # 32\n",
        "        x12d = self.do12d(F.relu(self.bn12d(self.conv12d(x1d))))\n",
        "        x11d = self.conv11d(x12d)\n",
        "        return x11d  # logits (B,1,H,W)\n"
      ],
      "metadata": {
        "id": "Paiptwqkrbrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Losses e Métricas"
      ],
      "metadata": {
        "id": "DeR9I4BgrmUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Losses & Métricas\n",
        "# =========================\n",
        "def dice_loss_from_logits(logits, targets, eps=1e-6):\n",
        "    probs = torch.sigmoid(logits)\n",
        "    num = 2.0 * (probs * targets).sum(dim=(2, 3)) + eps\n",
        "    den = probs.sum(dim=(2, 3)) + targets.sum(dim=(2, 3)) + eps\n",
        "    return 1.0 - (num / den).mean()\n",
        "\n",
        "def tversky_loss_from_logits(logits, targets, alpha=0.5, beta=0.5, eps=1e-6):\n",
        "    probs = torch.sigmoid(logits)\n",
        "    tp = (probs * targets).sum(dim=(2,3))\n",
        "    fp = (probs * (1 - targets)).sum(dim=(2,3))\n",
        "    fn = ((1 - probs) * targets).sum(dim=(2,3))\n",
        "    tversky = (tp + eps) / (tp + alpha*fp + beta*fn + eps)\n",
        "    return (1 - tversky).mean()\n",
        "\n",
        "class ComboLoss:\n",
        "    \"\"\"BCEWithLogits(pos_weight) + Dice (e opcional Tversky).\"\"\"\n",
        "    def __init__(self, bce_weight=0.5, pos_weight=None, use_tversky=False, tv_alpha=0.5, tv_beta=0.5):\n",
        "        self.bce_weight = bce_weight\n",
        "        self.pos_weight = pos_weight\n",
        "        self.use_tversky = use_tversky\n",
        "        self.tv_alpha = tv_alpha\n",
        "        self.tv_beta = tv_beta\n",
        "    def __call__(self, logits, targets):\n",
        "        bce = F.binary_cross_entropy_with_logits(\n",
        "            logits, targets, pos_weight=self.pos_weight\n",
        "        )\n",
        "        if self.use_tversky:\n",
        "            aux = tversky_loss_from_logits(logits, targets, alpha=self.tv_alpha, beta=self.tv_beta)\n",
        "        else:\n",
        "            aux = dice_loss_from_logits(logits, targets)\n",
        "        return self.bce_weight * bce + (1.0 - self.bce_weight) * aux\n",
        "\n",
        "@torch.no_grad()\n",
        "def iou_from_logits(logits, targets, thr=0.5, eps=1e-6):\n",
        "    probs = torch.sigmoid(logits)\n",
        "    preds = (probs > thr).float()\n",
        "    inter = (preds * targets).sum(dim=(2, 3))\n",
        "    union = preds.sum(dim=(2, 3)) + targets.sum(dim=(2, 3)) - inter + eps\n",
        "    return ((inter + eps) / union).mean().item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def dice_from_logits(logits, targets, thr=0.5, eps=1e-6):\n",
        "    probs = torch.sigmoid(logits)\n",
        "    preds = (probs > thr).float()\n",
        "    num = 2.0 * (preds * targets).sum(dim=(2, 3)) + eps\n",
        "    den = preds.sum(dim=(2, 3)) + targets.sum(dim=(2, 3)) + eps\n",
        "    return (num / den).mean().item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def roc_auc_from_loader(model, loader, max_points=50):\n",
        "    \"\"\"Calcula ROC AUC agregando todo o val (sem sklearn).\"\"\"\n",
        "    model.eval()\n",
        "    all_probs = []\n",
        "    all_true  = []\n",
        "    for t1, t2, y in loader:\n",
        "        t1, t2 = t1.to(device), t2.to(device)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            logits = model(t1, t2)\n",
        "            probs = torch.sigmoid(logits).detach().cpu().numpy()  # (B,1,H,W)\n",
        "        all_probs.append(probs.reshape(-1))\n",
        "        all_true.append(y.numpy().reshape(-1))\n",
        "    p = np.concatenate(all_probs)\n",
        "    g = np.concatenate(all_true).astype(np.uint8)\n",
        "    # evita casos degenerados\n",
        "    if g.max() == g.min():\n",
        "        return float('nan'), 0.5  # sem positivos/negativos → AUC indefinido\n",
        "    # Pontos de threshold uniformes em [0,1]\n",
        "    ths = np.linspace(0, 1, max_points)\n",
        "    tpr = []; fpr = []; best_thr = 0.5; best_j = -1.0\n",
        "    P = (g == 1).sum(); N = (g == 0).sum()\n",
        "    for th in ths:\n",
        "        pred = (p >= th).astype(np.uint8)\n",
        "        TP = np.logical_and(pred==1, g==1).sum()\n",
        "        FP = np.logical_and(pred==1, g==0).sum()\n",
        "        TN = np.logical_and(pred==0, g==0).sum()\n",
        "        FN = np.logical_and(pred==0, g==1).sum()\n",
        "        TPR = TP / max(P,1); FPR = FP / max(N,1)\n",
        "        tpr.append(TPR); fpr.append(FPR)\n",
        "        J = TPR - FPR\n",
        "        if J > best_j:\n",
        "            best_j = J; best_thr = float(th)\n",
        "    # AUC pelo método do trapézio (ordenar por FPR)\n",
        "    idx = np.argsort(fpr)\n",
        "    auc = np.trapz(np.array(tpr)[idx], np.array(fpr)[idx])\n",
        "    return float(auc), float(best_thr)\n"
      ],
      "metadata": {
        "id": "uTzvhhMurqvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split automático"
      ],
      "metadata": {
        "id": "0MajLrOSrtM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Split automático (estratificado por presença de mudança)\n",
        "# =========================\n",
        "\n",
        "def list_common_ids(T10_dir, T20_dir, mask_dir):\n",
        "    # função auxiliar que lista arquivos do diretório 'd' cujo nome\n",
        "    # começa com \"recorte_\" e termina com \".tif\"; retorna um CONJUNTO (set)\n",
        "    def rec(d): return {n for n in os.listdir(d) if n.startswith(\"recorte_\") and n.endswith(\".tif\")}\n",
        "    # interseção dos três conjuntos -> só os nomes que existem nas 3 pastas (T1, T2, máscara)\n",
        "    common = rec(T10_dir) & rec(T20_dir) & rec(mask_dir)\n",
        "    # para cada nome \"recorte_<ID>.tif\", extrai \"<ID>\" (tudo após o 1º \"_\") e remove \".tif\";\n",
        "    # devolve IDs ORDENADOS (list)\n",
        "    return sorted([n.split('_', 1)[1].replace('.tif', '') for n in common])\n",
        "\n",
        "def has_positive_change(mask_path):\n",
        "    # abre a máscara no caminho 'mask_path' com rasterio (somente leitura)\n",
        "    with rasterio.open(mask_path) as src:\n",
        "        # lê a banda 1 (array 2D de inteiros/float)\n",
        "        arr = src.read(1)\n",
        "        # True se existe pelo menos UM pixel > 0; False caso contrário\n",
        "        return bool((arr > 0).any())\n",
        "\n",
        "def stratified_ids_by_mask(mask_dir, ids, val_ratio=0.2, seed=42):\n",
        "    # RNG com semente fixa para reprodutibilidade do shuffle\n",
        "    rng = random.Random(seed)\n",
        "    pos, neg = [], []\n",
        "    # varre todos os IDs candidate e separa em positivos/negativos\n",
        "    for id_ in ids:\n",
        "        mpath = os.path.join(mask_dir, f\"recorte_{id_}.tif\")\n",
        "        if has_positive_change(mpath):\n",
        "            pos.append(id_)\n",
        "        else:\n",
        "            neg.append(id_)\n",
        "\n",
        "    # tamanho total e quantos vão para validação\n",
        "    n_total = len(ids)\n",
        "    n_val = max(1, int(round(n_total * val_ratio)))  # garante pelo menos 1\n",
        "\n",
        "    # caso \"normal\": há tanto positivos quanto negativos\n",
        "    if pos and neg:\n",
        "        # fração de positivos no conjunto completo\n",
        "        frac_pos = len(pos) / max(1, n_total)\n",
        "        # quantos positivos vão para val (proporcional à fração, mas com limites)\n",
        "        n_val_pos = min(len(pos), max(1, int(round(n_val * frac_pos))))\n",
        "        # o resto das vagas vai para negativos\n",
        "        n_val_neg = max(0, n_val - n_val_pos)\n",
        "        # embaralha as listas para amostrar sem viés\n",
        "        rng.shuffle(pos); rng.shuffle(neg)\n",
        "        # escolhe os primeiros n_val_pos/n_val_neg para compor a validação\n",
        "        val_ids = set(pos[:n_val_pos] + neg[:n_val_neg])\n",
        "        # treino é o complemento (tudo que não foi para val)\n",
        "        train_ids = [i for i in ids if i not in val_ids]\n",
        "        # retorna:\n",
        "        # - train_ids (lista)\n",
        "        # - val_ids ordenados (lista)\n",
        "        # - pos, neg (listas de TODOS os ids positivos/negativos, não só do treino)\n",
        "        return train_ids, sorted(list(val_ids)), pos, neg\n",
        "\n",
        "    # caso de borda: só há positivos OU só há negativos\n",
        "    ids_copy = ids[:]\n",
        "    rng.shuffle(ids_copy)\n",
        "    # escolhe n_val IDs aleatórios para validação\n",
        "    val_ids = set(ids_copy[:n_val])\n",
        "    # treino é o restante\n",
        "    train_ids = [i for i in ids if i not in val_ids]\n",
        "    # recalcula pos/neg **apenas no treino** (já que só existe uma classe no total)\n",
        "    pos_train, neg_train = [], []\n",
        "    for id_ in train_ids:\n",
        "        mpath = os.path.join(mask_dir, f\"recorte_{id_}.tif\")\n",
        "        (pos_train if has_positive_change(mpath) else neg_train).append(id_)\n",
        "    # retorna:\n",
        "    # - train_ids (lista)\n",
        "    # - val_ids ordenados (lista)\n",
        "    # - pos_train, neg_train (listas filtradas do treino)\n",
        "    return train_ids, sorted(list(val_ids)), pos_train, neg_train\n",
        "\n",
        "# =========================\n",
        "# Utilidades de balanceamento e pos_weight\n",
        "# =========================\n",
        "def compute_pixel_pos_weight(mask_dir, ids, clamp_max=None, use_sqrt=False):\n",
        "    \"\"\"\n",
        "    Calcula pos_weight para BCEWithLogits: (negativos / positivos) em nível de PIXEL.\n",
        "    - ids: lista de tiles do CONJUNTO DE TREINO.\n",
        "    - clamp_max: se informado, faz clamp do pos_weight para evitar explosões (ex.: 100).\n",
        "    - use_sqrt: se True, usa sqrt(neg/pos) em vez de (neg/pos) para suavizar.\n",
        "    \"\"\"\n",
        "    pos = 0; neg = 0\n",
        "    for id_ in ids:\n",
        "        p = os.path.join(mask_dir, f\"recorte_{id_}.tif\")\n",
        "        with rasterio.open(p) as src:\n",
        "            m = src.read(1)                        # lê a banda da máscara\n",
        "            m_bin = (m > 0).astype(np.uint8)      # assume 0 = neg, >0 = pos\n",
        "            pos += int(m_bin.sum())               # total de pixels positivos\n",
        "            neg += int(m_bin.size - m_bin.sum())  # total de pixels negativos\n",
        "\n",
        "    pos = max(pos, 1)                             # evita div/0 se não houver positivos\n",
        "    ratio = neg / pos\n",
        "    if use_sqrt:\n",
        "        ratio = ratio**0.5                        # suaviza o peso dos positivos\n",
        "\n",
        "    if clamp_max is not None:\n",
        "        ratio = min(ratio, clamp_max)             # limita peso máximo para estabilidade\n",
        "\n",
        "    # BCEWithLogitsLoss espera um tensor no device correto; shape [1] funciona\n",
        "    return torch.tensor([ratio], dtype=torch.float32, device=device)\n",
        "\n",
        "\n",
        "def make_weighted_sampler(train_ids, pos_ids, neg_ids, frac_pos=0.7):\n",
        "    \"\"\"\n",
        "    Oversampling em nível de TILE:\n",
        "    - Atribui mais peso para tiles com mudança (pos_ids).\n",
        "    - frac_pos: fração desejada de amostras positivas por época (ex.: 0.7 = 70%).\n",
        "    \"\"\"\n",
        "    pos_set = set(pos_ids)\n",
        "    neg_set = set(neg_ids)\n",
        "\n",
        "    # Se faltar alguma classe, caia para “sem sampler” (ou 100% da classe disponível).\n",
        "    if len(pos_set) == 0 and len(neg_set) == 0:\n",
        "        # Nada a amostrar – devolve um sampler trivial\n",
        "        return WeightedRandomSampler([1.0]*len(train_ids), num_samples=len(train_ids), replacement=True)\n",
        "    if len(pos_set) == 0:\n",
        "        # só negativos disponíveis\n",
        "        w_neg = 1.0 / max(len(neg_set), 1)\n",
        "        weights = [w_neg for _ in train_ids]\n",
        "        return WeightedRandomSampler(weights, num_samples=len(train_ids), replacement=True)\n",
        "    if len(neg_set) == 0:\n",
        "        # só positivos disponíveis\n",
        "        w_pos = 1.0 / max(len(pos_set), 1)\n",
        "        weights = [w_pos for _ in train_ids]\n",
        "        return WeightedRandomSampler(weights, num_samples=len(train_ids), replacement=True)\n",
        "\n",
        "    # pesos proporcionais ao alvo de fração de positivos\n",
        "    w_pos = frac_pos / max(len(pos_set), 1)\n",
        "    w_neg = (1.0 - frac_pos) / max(len(neg_set), 1)\n",
        "\n",
        "    weights = [w_pos if i in pos_set else w_neg for i in train_ids]\n",
        "    return WeightedRandomSampler(weights, num_samples=len(train_ids), replacement=True)\n",
        "# =========================\n",
        "# Utilidades de balanceamento e pos_weight\n",
        "# =========================\n",
        "def compute_pixel_pos_weight(mask_dir, ids, clamp_max=None, use_sqrt=False):\n",
        "    \"\"\"\n",
        "    Calcula pos_weight para BCEWithLogits: (negativos / positivos) em nível de PIXEL.\n",
        "    - ids: lista de tiles do CONJUNTO DE TREINO.\n",
        "    - clamp_max: se informado, faz clamp do pos_weight para evitar explosões (ex.: 100).\n",
        "    - use_sqrt: se True, usa sqrt(neg/pos) em vez de (neg/pos) para suavizar.\n",
        "    \"\"\"\n",
        "    pos = 0; neg = 0\n",
        "    for id_ in ids:\n",
        "        p = os.path.join(mask_dir, f\"recorte_{id_}.tif\")\n",
        "        with rasterio.open(p) as src:\n",
        "            m = src.read(1)                        # lê a banda da máscara\n",
        "            m_bin = (m > 0).astype(np.uint8)      # assume 0 = neg, >0 = pos\n",
        "            pos += int(m_bin.sum())               # total de pixels positivos\n",
        "            neg += int(m_bin.size - m_bin.sum())  # total de pixels negativos\n",
        "\n",
        "    pos = max(pos, 1)                             # evita div/0 se não houver positivos\n",
        "    ratio = neg / pos\n",
        "    if use_sqrt:\n",
        "        ratio = ratio**0.5                        # suaviza o peso dos positivos\n",
        "\n",
        "    if clamp_max is not None:\n",
        "        ratio = min(ratio, clamp_max)             # limita peso máximo para estabilidade\n",
        "\n",
        "    # BCEWithLogitsLoss espera um tensor no device correto; shape [1] funciona\n",
        "    return torch.tensor([ratio], dtype=torch.float32, device=device)\n",
        "\n",
        "\n",
        "def make_weighted_sampler(train_ids, pos_ids, neg_ids, frac_pos=0.7):\n",
        "    \"\"\"\n",
        "    Oversampling em nível de TILE:\n",
        "    - Atribui mais peso para tiles com mudança (pos_ids).\n",
        "    - frac_pos: fração desejada de amostras positivas por época (ex.: 0.7 = 70%).\n",
        "    \"\"\"\n",
        "    pos_set = set(pos_ids)\n",
        "    neg_set = set(neg_ids)\n",
        "\n",
        "\n",
        "    if len(pos_set) == 0 and len(neg_set) == 0:\n",
        "        # Nada a amostrar – devolve um sampler trivial\n",
        "        return WeightedRandomSampler([1.0]*len(train_ids), num_samples=len(train_ids), replacement=True)\n",
        "    if len(pos_set) == 0:\n",
        "        # só negativos disponíveis\n",
        "        w_neg = 1.0 / max(len(neg_set), 1)\n",
        "        weights = [w_neg for _ in train_ids]\n",
        "        return WeightedRandomSampler(weights, num_samples=len(train_ids), replacement=True)\n",
        "    if len(neg_set) == 0:\n",
        "        # só positivos disponíveis\n",
        "        w_pos = 1.0 / max(len(pos_set), 1)\n",
        "        weights = [w_pos for _ in train_ids]\n",
        "        return WeightedRandomSampler(weights, num_samples=len(train_ids), replacement=True)\n",
        "\n",
        "    # pesos proporcionais ao alvo de fração de positivos\n",
        "    w_pos = frac_pos / max(len(pos_set), 1)\n",
        "    w_neg = (1.0 - frac_pos) / max(len(neg_set), 1)\n",
        "\n",
        "    weights = [w_pos if i in pos_set else w_neg for i in train_ids]\n",
        "    return WeightedRandomSampler(weights, num_samples=len(train_ids), replacement=True)\n"
      ],
      "metadata": {
        "id": "OY4hkByDrwJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treino e Validação"
      ],
      "metadata": {
        "id": "JSpGeLcpr61C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Treino / Validação\n",
        "# =========================\n",
        "def train_one_epoch(model, loader, optimizer, criterion, scaler=None, max_norm=1.0):\n",
        "    model.train()\n",
        "    total_loss, total_iou, n = 0.0, 0.0, 0\n",
        "    for t1, t2, y in loader:\n",
        "        t1, t2, y = t1.to(device, non_blocking=True), t2.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            logits = model(t1, t2)\n",
        "            loss = criterion(logits, y)\n",
        "        if scaler is not None and device.type == \"cuda\":\n",
        "            scaler.scale(loss).backward()\n",
        "            # grad clipping\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
        "            optimizer.step()\n",
        "        bs = t1.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_iou  += iou_from_logits(logits, y) * bs\n",
        "        n += bs\n",
        "    return total_loss / n, total_iou / n\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, use_best_thr=False, last_best_thr=0.5):\n",
        "    model.eval()\n",
        "    total_loss, total_iou, total_dice, n = 0.0, 0.0, 0.0, 0\n",
        "    # calcula ROC AUC e threshold ótimo numa passada separada ao final\n",
        "    all_logits = []\n",
        "    all_targets = []\n",
        "    for t1, t2, y in loader:\n",
        "        t1, t2, y = t1.to(device, non_blocking=True), t2.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "        with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "            logits = model(t1, t2)\n",
        "            loss = criterion(logits, y)\n",
        "        bs = t1.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_iou  += iou_from_logits(logits, y, thr=last_best_thr if use_best_thr else 0.5) * bs\n",
        "        total_dice += dice_from_logits(logits, y,  thr=last_best_thr if use_best_thr else 0.5) * bs\n",
        "        n += bs\n",
        "        all_logits.append(logits.detach().cpu())\n",
        "        all_targets.append(y.detach().cpu())\n",
        "\n",
        "    # ROC AUC + best threshold (Youden J)\n",
        "    logits_cat  = torch.cat(all_logits, dim=0)\n",
        "    targets_cat = torch.cat(all_targets, dim=0)\n",
        "    probs = torch.sigmoid(logits_cat).numpy().reshape(-1)\n",
        "    truth = targets_cat.numpy().reshape(-1).astype(np.uint8)\n",
        "\n",
        "    if truth.max() != truth.min():\n",
        "        # Calcula em ~100 pontos\n",
        "        ths = np.linspace(0, 1, 100)\n",
        "        tpr = []; fpr = []; best_thr = 0.5; best_j = -1\n",
        "        P = (truth==1).sum(); N=(truth==0).sum()\n",
        "        for th in ths:\n",
        "            pred = (probs >= th).astype(np.uint8)\n",
        "            TP = np.logical_and(pred==1, truth==1).sum()\n",
        "            FP = np.logical_and(pred==1, truth==0).sum()\n",
        "            TN = np.logical_and(pred==0, truth==0).sum()\n",
        "            FN = np.logical_and(pred==0, truth==1).sum()\n",
        "            TPR = TP / max(P,1); FPR = FP / max(N,1)\n",
        "            tpr.append(TPR); fpr.append(FPR)\n",
        "            J = TPR - FPR\n",
        "            if J > best_j:\n",
        "                best_j = J; best_thr = float(th)\n",
        "        idx = np.argsort(fpr)\n",
        "        roc_auc = float(np.trapz(np.array(tpr)[idx], np.array(fpr)[idx]))\n",
        "    else:\n",
        "        roc_auc = float('nan'); best_thr = last_best_thr\n",
        "\n",
        "    return (total_loss / n, total_iou / n, total_dice / n, roc_auc, best_thr)\n"
      ],
      "metadata": {
        "id": "4uMMmai0r_8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Configuração e Execução"
      ],
      "metadata": {
        "id": "m_zcbcXIsFCD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTmCIfE03tFb",
        "outputId": "e8e2567d-a8fe-4422-a5e9-b39b96371d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de amostras: 945\n",
            "Split -> train: 756 | val: 189 | train_pos: 604 | train_neg: 341\n",
            "pos_weight(pixel) = 75.484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/tmp/ipython-input-2892845574.py:537: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  roc_auc = float(np.trapz(np.array(tpr)[idx], np.array(fpr)[idx]))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[01/50] train_loss=1.2693 IoU=0.026 | val_loss=0.8492 IoU@thr*=0.172 Dice@thr*=0.229 AUC=0.936 thr*=0.485 | best_IoU=0.172\n",
            "[02/50] train_loss=0.8897 IoU=0.089 | val_loss=0.5579 IoU@thr*=0.412 Dice@thr*=0.484 AUC=0.990 thr*=0.455 | best_IoU=0.412\n",
            "[03/50] train_loss=0.6984 IoU=0.186 | val_loss=1.1870 IoU@thr*=0.201 Dice@thr*=0.269 AUC=0.880 thr*=0.485 | best_IoU=0.412\n",
            "[04/50] train_loss=0.6213 IoU=0.242 | val_loss=0.4402 IoU@thr*=0.406 Dice@thr*=0.487 AUC=0.990 thr*=0.202 | best_IoU=0.412\n",
            "[05/50] train_loss=0.6456 IoU=0.296 | val_loss=0.4459 IoU@thr*=0.338 Dice@thr*=0.418 AUC=0.993 thr*=0.081 | best_IoU=0.412\n",
            "[06/50] train_loss=0.5221 IoU=0.330 | val_loss=0.3763 IoU@thr*=0.370 Dice@thr*=0.456 AUC=0.993 thr*=0.152 | best_IoU=0.412\n",
            "[07/50] train_loss=0.5034 IoU=0.375 | val_loss=0.4058 IoU@thr*=0.403 Dice@thr*=0.490 AUC=0.992 thr*=0.040 | best_IoU=0.412\n",
            "[08/50] train_loss=0.4601 IoU=0.398 | val_loss=0.3777 IoU@thr*=0.311 Dice@thr*=0.395 AUC=0.994 thr*=0.212 | best_IoU=0.412\n",
            "[09/50] train_loss=0.4492 IoU=0.393 | val_loss=0.4184 IoU@thr*=0.360 Dice@thr*=0.449 AUC=0.989 thr*=0.010 | best_IoU=0.412\n",
            "[10/50] train_loss=0.5115 IoU=0.378 | val_loss=0.3475 IoU@thr*=0.398 Dice@thr*=0.484 AUC=0.995 thr*=0.071 | best_IoU=0.412\n",
            "[11/50] train_loss=0.4716 IoU=0.394 | val_loss=0.3754 IoU@thr*=0.390 Dice@thr*=0.476 AUC=0.993 thr*=0.081 | best_IoU=0.412\n",
            "[12/50] train_loss=0.4227 IoU=0.378 | val_loss=0.3612 IoU@thr*=0.458 Dice@thr*=0.547 AUC=0.993 thr*=0.071 | best_IoU=0.458\n",
            "[13/50] train_loss=0.3992 IoU=0.403 | val_loss=0.3615 IoU@thr*=0.419 Dice@thr*=0.506 AUC=0.992 thr*=0.051 | best_IoU=0.458\n",
            "[14/50] train_loss=0.4450 IoU=0.404 | val_loss=0.3789 IoU@thr*=0.435 Dice@thr*=0.523 AUC=0.992 thr*=0.040 | best_IoU=0.458\n",
            "[15/50] train_loss=0.4453 IoU=0.434 | val_loss=0.3711 IoU@thr*=0.458 Dice@thr*=0.547 AUC=0.992 thr*=0.030 | best_IoU=0.458\n",
            "[16/50] train_loss=0.4347 IoU=0.404 | val_loss=0.3471 IoU@thr*=0.366 Dice@thr*=0.451 AUC=0.995 thr*=0.293 | best_IoU=0.458\n",
            "[17/50] train_loss=0.4138 IoU=0.409 | val_loss=0.3538 IoU@thr*=0.402 Dice@thr*=0.489 AUC=0.994 thr*=0.364 | best_IoU=0.458\n",
            "[18/50] train_loss=0.4031 IoU=0.401 | val_loss=0.3559 IoU@thr*=0.382 Dice@thr*=0.470 AUC=0.993 thr*=0.121 | best_IoU=0.458\n",
            "[19/50] train_loss=0.3801 IoU=0.422 | val_loss=0.3695 IoU@thr*=0.451 Dice@thr*=0.537 AUC=0.993 thr*=0.354 | best_IoU=0.458\n",
            "[20/50] train_loss=0.3982 IoU=0.410 | val_loss=0.3361 IoU@thr*=0.426 Dice@thr*=0.514 AUC=0.995 thr*=0.081 | best_IoU=0.458\n",
            "[21/50] train_loss=0.4473 IoU=0.446 | val_loss=0.3436 IoU@thr*=0.440 Dice@thr*=0.528 AUC=0.995 thr*=0.323 | best_IoU=0.458\n",
            "[22/50] train_loss=0.4097 IoU=0.402 | val_loss=0.3439 IoU@thr*=0.437 Dice@thr*=0.526 AUC=0.994 thr*=0.455 | best_IoU=0.458\n",
            "[23/50] train_loss=0.3860 IoU=0.400 | val_loss=0.3420 IoU@thr*=0.464 Dice@thr*=0.553 AUC=0.994 thr*=0.101 | best_IoU=0.464\n",
            "[24/50] train_loss=0.3930 IoU=0.418 | val_loss=0.3274 IoU@thr*=0.427 Dice@thr*=0.516 AUC=0.995 thr*=0.172 | best_IoU=0.464\n",
            "[25/50] train_loss=0.3760 IoU=0.420 | val_loss=0.3412 IoU@thr*=0.488 Dice@thr*=0.576 AUC=0.994 thr*=0.242 | best_IoU=0.488\n",
            "[26/50] train_loss=0.4056 IoU=0.448 | val_loss=0.3408 IoU@thr*=0.413 Dice@thr*=0.503 AUC=0.994 thr*=0.051 | best_IoU=0.488\n",
            "[27/50] train_loss=0.3610 IoU=0.427 | val_loss=0.3455 IoU@thr*=0.433 Dice@thr*=0.522 AUC=0.993 thr*=0.040 | best_IoU=0.488\n",
            "[28/50] train_loss=0.4070 IoU=0.404 | val_loss=0.3470 IoU@thr*=0.429 Dice@thr*=0.518 AUC=0.994 thr*=0.111 | best_IoU=0.488\n",
            "[29/50] train_loss=0.3879 IoU=0.437 | val_loss=0.3465 IoU@thr*=0.435 Dice@thr*=0.524 AUC=0.993 thr*=0.061 | best_IoU=0.488\n",
            "[30/50] train_loss=0.3518 IoU=0.442 | val_loss=0.3481 IoU@thr*=0.443 Dice@thr*=0.533 AUC=0.993 thr*=0.071 | best_IoU=0.488\n",
            "[31/50] train_loss=0.4035 IoU=0.415 | val_loss=0.3326 IoU@thr*=0.457 Dice@thr*=0.547 AUC=0.994 thr*=0.121 | best_IoU=0.488\n",
            "[32/50] train_loss=0.3865 IoU=0.395 | val_loss=0.3267 IoU@thr*=0.437 Dice@thr*=0.525 AUC=0.995 thr*=0.313 | best_IoU=0.488\n",
            "[33/50] train_loss=0.3551 IoU=0.432 | val_loss=0.3338 IoU@thr*=0.432 Dice@thr*=0.522 AUC=0.994 thr*=0.051 | best_IoU=0.488\n",
            "[34/50] train_loss=0.3798 IoU=0.440 | val_loss=0.3342 IoU@thr*=0.435 Dice@thr*=0.524 AUC=0.994 thr*=0.091 | best_IoU=0.488\n",
            "[35/50] train_loss=0.3463 IoU=0.434 | val_loss=0.3381 IoU@thr*=0.434 Dice@thr*=0.523 AUC=0.994 thr*=0.040 | best_IoU=0.488\n",
            "[36/50] train_loss=0.3600 IoU=0.468 | val_loss=0.3365 IoU@thr*=0.412 Dice@thr*=0.502 AUC=0.994 thr*=0.020 | best_IoU=0.488\n",
            "[37/50] train_loss=0.3579 IoU=0.453 | val_loss=0.3384 IoU@thr*=0.429 Dice@thr*=0.518 AUC=0.994 thr*=0.030 | best_IoU=0.488\n",
            "[38/50] train_loss=0.3780 IoU=0.446 | val_loss=0.3330 IoU@thr*=0.430 Dice@thr*=0.520 AUC=0.994 thr*=0.040 | best_IoU=0.488\n",
            "[39/50] train_loss=0.3909 IoU=0.433 | val_loss=0.3249 IoU@thr*=0.433 Dice@thr*=0.522 AUC=0.995 thr*=0.071 | best_IoU=0.488\n",
            "[40/50] train_loss=0.3517 IoU=0.426 | val_loss=0.3306 IoU@thr*=0.429 Dice@thr*=0.518 AUC=0.994 thr*=0.040 | best_IoU=0.488\n",
            "[41/50] train_loss=0.3442 IoU=0.477 | val_loss=0.3307 IoU@thr*=0.434 Dice@thr*=0.523 AUC=0.994 thr*=0.040 | best_IoU=0.488\n",
            "[42/50] train_loss=0.3515 IoU=0.446 | val_loss=0.3239 IoU@thr*=0.422 Dice@thr*=0.511 AUC=0.995 thr*=0.061 | best_IoU=0.488\n",
            "[43/50] train_loss=0.3567 IoU=0.447 | val_loss=0.3321 IoU@thr*=0.445 Dice@thr*=0.534 AUC=0.994 thr*=0.141 | best_IoU=0.488\n",
            "[44/50] train_loss=0.3544 IoU=0.456 | val_loss=0.3288 IoU@thr*=0.432 Dice@thr*=0.522 AUC=0.994 thr*=0.051 | best_IoU=0.488\n",
            "[45/50] train_loss=0.4560 IoU=0.446 | val_loss=0.3266 IoU@thr*=0.417 Dice@thr*=0.506 AUC=0.995 thr*=0.061 | best_IoU=0.488\n",
            "[46/50] train_loss=0.3749 IoU=0.463 | val_loss=0.3321 IoU@thr*=0.417 Dice@thr*=0.507 AUC=0.994 thr*=0.020 | best_IoU=0.488\n",
            "[47/50] train_loss=0.3417 IoU=0.446 | val_loss=0.3284 IoU@thr*=0.426 Dice@thr*=0.516 AUC=0.994 thr*=0.040 | best_IoU=0.488\n",
            "[48/50] train_loss=0.3700 IoU=0.434 | val_loss=0.3260 IoU@thr*=0.404 Dice@thr*=0.493 AUC=0.995 thr*=0.091 | best_IoU=0.488\n",
            "[49/50] train_loss=0.3380 IoU=0.466 | val_loss=0.3265 IoU@thr*=0.412 Dice@thr*=0.501 AUC=0.995 thr*=0.061 | best_IoU=0.488\n",
            "[50/50] train_loss=0.3770 IoU=0.450 | val_loss=0.3290 IoU@thr*=0.435 Dice@thr*=0.525 AUC=0.994 thr*=0.051 | best_IoU=0.488\n",
            "Treino finalizado. Melhor checkpoint salvo em: siamunet_scSE_best.pth\n",
            "Melhor threshold valid: 0.242\n",
            "Histórico salvo em: training_history_scSE.csv\n",
            "Figura salva: fig_loss_train.png\n",
            "Figura salva: fig_loss_val.png\n",
            "Figura salva: fig_iou_train.png\n",
            "Figura salva: fig_iou_val.png\n",
            "Figura salva: fig_dice_val.png\n",
            "Figura salva: fig_auc_val.png\n",
            "Pred shape: torch.Size([8, 1, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Config e Execução\n",
        "# =========================\n",
        "# caminhos das pastas\n",
        "T10_dir  = \"/content/drive/MyDrive/WorkCap/dataset_kaggle/dataset/t1\"\n",
        "T20_dir  = \"/content/drive/MyDrive/WorkCap/dataset_kaggle/dataset/t2\"\n",
        "mask_dir = \"/content/drive/MyDrive/WorkCap/dataset_kaggle/dataset/mask\"\n",
        "\n",
        "VAL_RATIO = 0.2\n",
        "BATCH_SIZE = 8            # um pouco maior ajuda o OneCycleLR (ajuste conforme VRAM)\n",
        "EPOCHS = 50               # mais épocas – com early stopping prático via best ckpt\n",
        "LR_MAX = 3e-3             # pico do OneCycle\n",
        "WD = 1e-4\n",
        "GRAD_MAX_NORM = 1.0\n",
        "\n",
        "# 1) Descobrir IDs e fazer split estratificado\n",
        "ids_all = list_common_ids(T10_dir, T20_dir, mask_dir)\n",
        "print(f\"Total de amostras: {len(ids_all)}\")\n",
        "\n",
        "train_ids, val_ids, pos_train_ids, neg_train_ids = stratified_ids_by_mask(mask_dir, ids_all, val_ratio=VAL_RATIO, seed=42)\n",
        "print(f\"Split -> train: {len(train_ids)} | val: {len(val_ids)} | train_pos: {len(pos_train_ids)} | train_neg: {len(neg_train_ids)}\")\n",
        "\n",
        "# 2) Datasets\n",
        "train_tf = JointAugment()\n",
        "val_tf = None\n",
        "train_ds = SiameseDataset(T10_dir, T20_dir, mask_dir, transform=train_tf, ids=train_ids)\n",
        "val_ds   = SiameseDataset(T10_dir, T20_dir, mask_dir, transform=val_tf,   ids=val_ids)\n",
        "\n",
        "# 3) DataLoaders (sampler balanceado para treino)\n",
        "num_workers = 4\n",
        "sampler = make_weighted_sampler(train_ids, pos_train_ids, neg_train_ids)\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=num_workers, pin_memory=True, drop_last=False)\n",
        "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,     num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "# 4) Modelo, loss, otimizador, scheduler\n",
        "c_in = train_ds[0][0].shape[0]   # nº de bandas em T1 (igual a T2)\n",
        "model = SiamUnet_diff(n_channels=c_in, n_classes=1, enable_attention=True, attn_reduction=8).to(device)\n",
        "\n",
        "# pos_weight por pixels no treino\n",
        "pos_weight = compute_pixel_pos_weight(mask_dir, train_ids)\n",
        "print(f\"pos_weight(pixel) = {pos_weight.item():.3f}\")\n",
        "\n",
        "criterion = ComboLoss(bce_weight=0.6, pos_weight=pos_weight, use_tversky=False)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR_MAX, weight_decay=WD)\n",
        "\n",
        "# OneCycleLR: define steps_per_epoch pelo train_dl\n",
        "steps_per_epoch = math.ceil(len(train_dl))\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=LR_MAX,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    pct_start=0.1, div_factor=10.0, final_div_factor=1e2\n",
        ")\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda', enabled=(device.type==\"cuda\"))\n",
        "\n",
        "# 5) Loop de treino com checkpoint no melhor IoU (thr adaptativo por ROC)\n",
        "best_iou = -1.0\n",
        "best_thr = 0.5\n",
        "ckpt_path = \"siamunet_scSE_best.pth\"\n",
        "\n",
        "hist = {\n",
        "    \"epoch\": [],\n",
        "    \"train_loss\": [],\n",
        "    \"train_iou\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_iou\": [],\n",
        "    \"val_dice\": [],\n",
        "    \"val_roc_auc\": [],\n",
        "    \"best_thr\": [],\n",
        "    \"lr\": []\n",
        "}\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    tr_loss, tr_iou = train_one_epoch(model, train_dl, optimizer, criterion, scaler, max_norm=GRAD_MAX_NORM)\n",
        "    # -> Chamaremos manualmente por batch seria o ideal; alternativa: usar scheduler.step() por iteração.\n",
        "    # Para simplicidade (e compatibilidade), chamamos aqui um step extra proporcional:\n",
        "    for _ in range(max(1, steps_per_epoch)):\n",
        "        scheduler.step()\n",
        "\n",
        "    va_loss, va_iou, va_dice, va_auc, thr_opt = evaluate(model, val_dl, criterion, use_best_thr=False, last_best_thr=best_thr)\n",
        "    # Re-avalia com threshold ótimo encontrado, só para logging de IoU/Dice com thr ótimo\n",
        "    va_loss2, va_iou2, va_dice2, _, _ = evaluate(model, val_dl, criterion, use_best_thr=True, last_best_thr=thr_opt)\n",
        "\n",
        "    # salvar melhor por IoU (com thr ótimo)\n",
        "    if va_iou2 > best_iou:\n",
        "        best_iou = va_iou2\n",
        "        best_thr = thr_opt\n",
        "        torch.save({\n",
        "            \"model\": model.state_dict(),\n",
        "            \"epoch\": epoch,\n",
        "            \"val_iou\": va_iou2,\n",
        "            \"val_dice\": va_dice2,\n",
        "            \"val_auc\": va_auc,\n",
        "            \"best_thr\": best_thr,\n",
        "            \"c_in\": c_in\n",
        "        }, ckpt_path)\n",
        "\n",
        "    # LR atual (primeiro param group)\n",
        "    cur_lr = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "    # log\n",
        "    hist[\"epoch\"].append(epoch)\n",
        "    hist[\"train_loss\"].append(tr_loss)\n",
        "    hist[\"train_iou\"].append(tr_iou)\n",
        "    hist[\"val_loss\"].append(va_loss)\n",
        "    hist[\"val_iou\"].append(va_iou2)   # com thr ótimo\n",
        "    hist[\"val_dice\"].append(va_dice2) # com thr ótimo\n",
        "    hist[\"val_roc_auc\"].append(va_auc)\n",
        "    hist[\"best_thr\"].append(thr_opt)\n",
        "    hist[\"lr\"].append(cur_lr)\n",
        "\n",
        "    print(f\"[{epoch:02d}/{EPOCHS}] \"\n",
        "          f\"train_loss={tr_loss:.4f} IoU={tr_iou:.3f} | \"\n",
        "          f\"val_loss={va_loss:.4f} IoU@thr*={va_iou2:.3f} Dice@thr*={va_dice2:.3f} AUC={va_auc:.3f} thr*={thr_opt:.3f} | \"\n",
        "          f\"best_IoU={best_iou:.3f}\")\n",
        "\n",
        "print(\"Treino finalizado. Melhor checkpoint salvo em:\", ckpt_path)\n",
        "print(f\"Melhor threshold valid: {best_thr:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Salvando histórico em CSV; Gráficos; Inferência rápida"
      ],
      "metadata": {
        "id": "PGObnmtdslmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Salvar histórico em CSV\n",
        "# -------------------------\n",
        "hist_path = \"training_history_scSE.csv\"\n",
        "with open(hist_path, \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow(list(hist.keys()))\n",
        "    for i in range(len(hist[\"epoch\"])):\n",
        "        w.writerow([hist[k][i] for k in hist.keys()])\n",
        "print(\"Histórico salvo em:\", hist_path)\n",
        "\n",
        "# -------------------------\n",
        "# Gráficos (Loss, IoU, Dice, ROC AUC)\n",
        "# -------------------------\n",
        "def plot_and_save(x, y, title, ylabel, out_png):\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(x, y)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Época\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.grid(True, ls=\"--\", alpha=0.4)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_png, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "    print(\"Figura salva:\", out_png)\n",
        "\n",
        "ep = hist[\"epoch\"]\n",
        "plot_and_save(ep, hist[\"train_loss\"], \"Loss (Treino)\", \"Loss\", \"fig_loss_train.png\")\n",
        "plot_and_save(ep, hist[\"val_loss\"],   \"Loss (Val)\",    \"Loss\", \"fig_loss_val.png\")\n",
        "plot_and_save(ep, hist[\"train_iou\"],  \"IoU (Treino)\",  \"IoU\",  \"fig_iou_train.png\")\n",
        "plot_and_save(ep, hist[\"val_iou\"],    \"IoU (Val)\",     \"IoU\",  \"fig_iou_val.png\")\n",
        "plot_and_save(ep, hist[\"val_dice\"],   \"Dice (Val)\",    \"Dice\", \"fig_dice_val.png\")\n",
        "plot_and_save(ep, hist[\"val_roc_auc\"],\"ROC AUC (Val)\", \"AUC\",  \"fig_auc_val.png\")\n",
        "\n",
        "# -------------------------\n",
        "# Inferência rápida em um minibatch de validação\n",
        "# -------------------------\n",
        "@torch.no_grad()\n",
        "def predict_batch(model, t1, t2, thr=0.5):\n",
        "    model.eval()\n",
        "    with torch.amp.autocast('cuda', enabled=(device.type=='cuda')):\n",
        "        logits = model(t1.to(device), t2.to(device))\n",
        "        probs = torch.sigmoid(logits)\n",
        "    preds = (probs > thr).float()\n",
        "    return preds.cpu(), probs.cpu()\n",
        "\n",
        "for t1b, t2b, mb in val_dl:\n",
        "    preds, probs = predict_batch(model, t1b, t2b, thr=best_thr)\n",
        "    print(\"Pred shape:\", preds.shape)  # (B,1,H,W)\n",
        "    break\n"
      ],
      "metadata": {
        "id": "SfjF2R1OsioN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualizando gráficos"
      ],
      "metadata": {
        "id": "jogtwPy1s3EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ep = hist[\"epoch\"]\n",
        "\n",
        "fig, axes = plt.subplots(3, 2, figsize=(12, 12))  # 3 linhas x 2 colunas\n",
        "\n",
        "# Loss (Treino)\n",
        "axes[0,0].plot(ep, hist[\"train_loss\"])\n",
        "axes[0,0].set_title(\"Loss (Treino)\")\n",
        "axes[0,0].set_xlabel(\"Epoch\"); axes[0,0].set_ylabel(\"Loss\")\n",
        "axes[0,0].grid(True, ls=\"--\", alpha=0.4)\n",
        "\n",
        "# Loss (Val)\n",
        "axes[0,1].plot(ep, hist[\"val_loss\"])\n",
        "axes[0,1].set_title(\"Loss (Val)\")\n",
        "axes[0,1].set_xlabel(\"Epoch\"); axes[0,1].set_ylabel(\"Loss\")\n",
        "axes[0,1].grid(True, ls=\"--\", alpha=0.4)\n",
        "\n",
        "# IoU (Treino)\n",
        "axes[1,0].plot(ep, hist[\"train_iou\"])\n",
        "axes[1,0].set_title(\"IoU (Treino)\")\n",
        "axes[1,0].set_xlabel(\"Epoch\"); axes[1,0].set_ylabel(\"IoU\")\n",
        "axes[1,0].grid(True, ls=\"--\", alpha=0.4)\n",
        "\n",
        "# IoU (Val)\n",
        "axes[1,1].plot(ep, hist[\"val_iou\"])\n",
        "axes[1,1].set_title(\"IoU (Val)\")\n",
        "axes[1,1].set_xlabel(\"Epoch\"); axes[1,1].set_ylabel(\"IoU\")\n",
        "axes[1,1].grid(True, ls=\"--\", alpha=0.4)\n",
        "\n",
        "# Dice (Val)\n",
        "axes[2,0].plot(ep, hist[\"val_dice\"])\n",
        "axes[2,0].set_title(\"Dice (Val)\")\n",
        "axes[2,0].set_xlabel(\"Epoch\"); axes[2,0].set_ylabel(\"Dice\")\n",
        "axes[2,0].grid(True, ls=\"--\", alpha=0.4)\n",
        "\n",
        "# ROC AUC (Val)\n",
        "axes[2,1].plot(ep, hist[\"val_roc_auc\"])\n",
        "axes[2,1].set_title(\"ROC AUC (Val)\")\n",
        "axes[2,1].set_xlabel(\"Epoch\"); axes[2,1].set_ylabel(\"AUC\")\n",
        "axes[2,1].grid(True, ls=\"--\", alpha=0.4)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aK__qTlSs3q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79gMUN6AlobH"
      },
      "source": [
        "#Inferência"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ou_gCLXu7M0t"
      },
      "outputs": [],
      "source": [
        "# ---------- CONFIG ----------\n",
        "# Configuração: Definição das variáveis e caminhos necessários para a execução do script.\n",
        "T10_INF = \"/content/drive/MyDrive/WorkCap/dataset_kaggle/avaliacao/t1\"\n",
        "T20_INF = \"/content/drive/MyDrive/WorkCap/dataset_kaggle/avaliacao/t2\"\n",
        "CKPT_PATH = \"siamunet_diff_best.pth\"\n",
        "OUT_DIR = \"/content/preds_siamunet\"\n",
        "SHOW_MAX = 315\n",
        "THRESH = 0.4\n",
        "SAVE_OUTPUTS = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ---------- Utilitários  ----------\n",
        "# Funções auxiliares para manipulação de arquivos,\n",
        "# leitura de imagens, visualização e salvamento de resultados.\n",
        "if 'list_common_recortes' not in globals():\n",
        "    def list_common_recortes(d1, d2):\n",
        "        f = lambda d: {n for n in os.listdir(d) if n.startswith(\"recorte_\") and n.endswith(\".tif\")}\n",
        "        return sorted(list(f(d1) & f(d2)))\n",
        "\n",
        "if 'read_image_norm' not in globals():\n",
        "    def read_image_norm(path):\n",
        "        with rasterio.open(path) as src:\n",
        "            img = src.read().astype(np.float32)  # (C,H,W)\n",
        "            img = np.nan_to_num(img, nan=0.0)\n",
        "            mn, mx = img.min(), img.max()\n",
        "            if mx > mn:\n",
        "                img = (img - mn) / (mx - mn)\n",
        "            else:\n",
        "                img[:] = 0.0\n",
        "            prof = src.profile\n",
        "        return torch.from_numpy(img), prof  # (C,H,W), profile\n",
        "\n",
        "if 'show_triplet' not in globals():\n",
        "    def show_triplet(t1, t2, mbin, title=None, save_path=None):\n",
        "        def to_rgb_first3(t):\n",
        "            c, h, w = t.shape\n",
        "            if c >= 3:\n",
        "                rgb = torch.stack([t[0], t[1], t[2]], dim=0).permute(1,2,0).cpu().numpy()\n",
        "            else:\n",
        "                g = t[0].cpu().numpy()\n",
        "                rgb = np.stack([g,g,g], axis=-1)\n",
        "            return np.clip(rgb, 0, 1)\n",
        "\n",
        "        rgb1 = to_rgb_first3(t1)\n",
        "        rgb2 = to_rgb_first3(t2)\n",
        "        mnp  = mbin.cpu().numpy()\n",
        "\n",
        "        plt.figure(figsize=(12,4))\n",
        "        plt.subplot(1,3,1); plt.imshow(rgb1); plt.title(\"T1\"); plt.axis(\"off\")\n",
        "        plt.subplot(1,3,2); plt.imshow(rgb2); plt.title(\"T2\"); plt.axis(\"off\")\n",
        "        plt.subplot(1,3,3); plt.imshow(mnp);  plt.title(\"Máscara (binária)\"); plt.axis(\"off\")\n",
        "        if title: plt.suptitle(title, y=0.98)\n",
        "        plt.tight_layout()\n",
        "        if save_path is not None:\n",
        "            Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "            plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "if 'save_geotiff_like' not in globals():\n",
        "    def save_geotiff_like(ref_profile, out_path, array, as_uint8=True):\n",
        "        prof = ref_profile.copy()\n",
        "        prof.update({\"count\": 1, \"compress\": \"lzw\"})\n",
        "        if as_uint8:\n",
        "            arr = (array * 255).astype(np.uint8) if array.dtype != np.uint8 else array\n",
        "            prof.update({\"dtype\": rasterio.uint8})\n",
        "        else:\n",
        "            arr = array.astype(np.float32)\n",
        "            prof.update({\"dtype\": rasterio.float32})\n",
        "        Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "        with rasterio.open(out_path, \"w\", **prof) as dst:\n",
        "            dst.write(arr, 1)\n",
        "\n",
        "# ---------- Modelo (reutiliza o já instanciado) ----------\n",
        "# supõe que `model` JÁ existe na RAM; se quiser recarregar pesos do ckpt, descomente:\n",
        "# ckpt = torch.load(CKPT_PATH, map_location=device)\n",
        "# model.load_state_dict(ckpt[\"model\"], strict=True)\n",
        "\n",
        "model.to(device).eval()\n",
        "\n",
        "# ---------- LOOP DE INFERÊNCIA ----------\n",
        "# Loop Principal Itera sobre os pares de imagens, executa o modelo e salva/exibe os resultados\n",
        "# Obtém a lista de nomes de arquivos de imagem que existem em ambos os diretórios (T1 e T2)\n",
        "ids = list_common_recortes(T10_INF, T20_INF)\n",
        "print(f\"Pares encontrados para inferência: {len(ids)}\")\n",
        "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "shown = 0\n",
        "for name in ids:\n",
        "    t1, prof1 = read_image_norm(os.path.join(T10_INF, name))\n",
        "    t2, _     = read_image_norm(os.path.join(T20_INF, name))\n",
        "    H, W = t1.shape[-2], t1.shape[-1]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(t1.unsqueeze(0).to(device), t2.unsqueeze(0).to(device))  # (1,1,h,w)\n",
        "        probs  = torch.sigmoid(logits)[0,0]  # (h,w)\n",
        "        if probs.shape[-2:] != (H, W):\n",
        "            probs = F.interpolate(probs.unsqueeze(0).unsqueeze(0), size=(H,W),\n",
        "                                  mode=\"bilinear\", align_corners=False)[0,0]\n",
        "        m_bin = (probs > THRESH).float().cpu()\n",
        "\n",
        "    # Mostrar\n",
        "    # Exibe o resultado se o limite de visualização não foi atingido\n",
        "    if shown < SHOW_MAX:\n",
        "        show_triplet(\n",
        "            t1, t2, m_bin,\n",
        "            title=name,\n",
        "            save_path=(Path(OUT_DIR)/\"figs\"/f\"{name}.png\" if SAVE_OUTPUTS else None)\n",
        "        )\n",
        "        shown += 1\n",
        "\n",
        "    # Salvar GeoTIFFs\n",
        "    #  Salva os resultados em formato GeoTIFF se a flag estiver ativa\n",
        "    if SAVE_OUTPUTS:\n",
        "        save_geotiff_like(prof1, str(Path(OUT_DIR)/\"tif_prob\"/name),\n",
        "                          probs.cpu().numpy().astype(np.float32), as_uint8=False)\n",
        "        save_geotiff_like(prof1, str(Path(OUT_DIR)/\"tif_bin\"/name),\n",
        "                          m_bin.numpy().astype(np.uint8), as_uint8=True)\n",
        "\n",
        "print(\"Inferência concluída.\")\n",
        "print(f\"Saídas em: {OUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72nhVXwolt1w"
      },
      "source": [
        "#Salvar predições em CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfu0nfOX-NZi",
        "outputId": "f4611298-aaec-4139-e795-3be2373ea9ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n",
            "T1 válidos: 315 | T2 válidos: 325 | IDs em comum: 315\n",
            "Só em T2 (10): ['recorte_3 (1)', 'recorte_30 (1)', 'recorte_298 (1)', 'recorte_299 (1)', 'recorte_300 (1)', 'recorte_301 (1)', 'recorte_302 (1)', 'recorte_303 (1)', 'recorte_304 (1)', 'recorte_305 (1)'] ...\n",
            "Header: 128x128(16384 px), C=4\n",
            "Modelo existente utilizado\n",
            "Progresso: 25/315 pares...\n",
            "Progresso: 50/315 pares...\n",
            "Progresso: 75/315 pares...\n",
            "Progresso: 100/315 pares...\n",
            "Progresso: 125/315 pares...\n",
            "Progresso: 150/315 pares...\n",
            "Progresso: 175/315 pares...\n",
            "Progresso: 200/315 pares...\n",
            "Progresso: 225/315 pares...\n",
            "Progresso: 250/315 pares...\n",
            "Progresso: 275/315 pares...\n",
            "Progresso: 300/315 pares...\n",
            "CSV binário salvo em: Siamunet_attentionscSE.csv\n"
          ]
        }
      ],
      "source": [
        "# --------------------------\n",
        "# CONFIG (ajuste os caminhos)\n",
        "# --------------------------\n",
        "t1_dir = \"/content/drive/MyDrive/WorkCap/dataset_kaggle/avaliacao/t1\"\n",
        "t2_dir = \"/content/drive/MyDrive/WorkCap/dataset_kaggle/avaliacao/t2\"\n",
        "csv_path = \"Siamunet_attentionscSE.csv\"      # saída (binária 0/1)\n",
        "save_probs_csv = False                        # também salvar probabilidades?\n",
        "probs_csv_path = \"predicted_change_probs.csv\" # se True acima\n",
        "THRESH = 0.4\n",
        "\n",
        "# Se você já tem `model` com pesos na memória, deixe False.\n",
        "LOAD_FROM_CKPT = False\n",
        "CKPT_PATH = \"siamunet_diff_best.pth\"\n",
        "\n",
        "VALID_EXTS = {\".tif\", \".tiff\"}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# --------------------------\n",
        "# Utilitários\n",
        "# --------------------------\n",
        "def natural_key(s: str):\n",
        "    \"\"\"Ordena 'recorte2' < 'recorte10' (1,2,3,...,10,11,...)\"\"\"\n",
        "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', s)]\n",
        "\n",
        "def list_images_by_id(folder):\n",
        "    \"\"\"Retorna dict: {nome_sem_ext: caminho_completo}, filtrando por .tif/.tiff\"\"\"\n",
        "    out = {}\n",
        "    for name in os.listdir(folder):\n",
        "        if name.startswith('.'):\n",
        "            continue\n",
        "        path = os.path.join(folder, name)\n",
        "        if not os.path.isfile(path):\n",
        "            continue\n",
        "        root, ext = os.path.splitext(name)\n",
        "        if ext.lower() not in VALID_EXTS:\n",
        "            continue\n",
        "        out[root] = path\n",
        "    return out\n",
        "\n",
        "def read_image_minmax(path):\n",
        "    \"\"\"Lê TIFF (todas bandas) e normaliza por tile para [0,1].\"\"\"\n",
        "    with rasterio.open(path) as src:\n",
        "        img = src.read().astype(np.float32)  # (C,H,W)\n",
        "        img = np.nan_to_num(img, nan=0.0)\n",
        "        mn, mx = img.min(), img.max()\n",
        "        if mx > mn:\n",
        "            img = (img - mn) / (mx - mn)\n",
        "        else:\n",
        "            img[:] = 0.0\n",
        "    return torch.from_numpy(img)  # (C,H,W) float32\n",
        "\n",
        "# --------------------------\n",
        "# Preparar dados e modelo\n",
        "# Cria mapeamentos de ID para caminho de arquivo para T1 e T2\n",
        "t1_map = list_images_by_id(t1_dir)\n",
        "t2_map = list_images_by_id(t2_dir)\n",
        "\n",
        "# Encontra a interseção de IDs (arquivos com mesmo nome base)\n",
        "\n",
        "ids_t1 = set(t1_map.keys())\n",
        "ids_t2 = set(t2_map.keys())\n",
        "\n",
        "# ORDEM NATURAL PELO NOME\n",
        "common_ids = sorted(ids_t1 & ids_t2, key=natural_key)\n",
        "only_t1 = sorted(ids_t1 - ids_t2, key=natural_key)\n",
        "only_t2 = sorted(ids_t2 - ids_t1, key=natural_key)\n",
        "\n",
        "# Assume que todas as imagens têm as mesmas dimensões.\n",
        "# Usa o primeiro par de imagens para definir o cabeçalho do CSV.\n",
        "print(f\"T1 válidos: {len(ids_t1)} | T2 válidos: {len(ids_t2)} | IDs em comum: {len(common_ids)}\")\n",
        "if only_t1: print(f\"Só em T1 ({len(only_t1)}): {only_t1[:10]} ...\")\n",
        "if only_t2: print(f\"Só em T2 ({len(only_t2)}): {only_t2[:10]} ...\")\n",
        "assert len(common_ids) > 0, \"Não há interseção de nomes entre T1 e T2.\"\n",
        "\n",
        "# Header (H, W, C) a partir do primeiro par\n",
        "first_id = common_ids[0]\n",
        "with rasterio.open(t1_map[first_id]) as src0:\n",
        "    C = src0.count\n",
        "    H, W = src0.height, src0.width\n",
        "num_pixels = H * W\n",
        "header = [\"id\"] + [f\"pixel_{i}\" for i in range(num_pixels)]\n",
        "print(f\"Header: {H}x{W}({num_pixels} px), C={C}\")\n",
        "\n",
        "# --------------------------\n",
        "# Modelo (reutiliza o existente se LOAD_FROM_CKPT=False)\n",
        "# --------------------------\n",
        "if LOAD_FROM_CKPT:\n",
        "    # Recrie o MESMO modelo usado no treino antes de carregar (com atenção)\n",
        "    # Certifique-se de que a classe SiamUnet_diff está definida\n",
        "    model = SiamUnet_diff(n_channels=C, n_classes=1, use_scse=True, scse_reduction=16, fuse_mode='absdiff').to(device)\n",
        "    ckpt = torch.load(CKPT_PATH, map_location=device)\n",
        "    model.load_state_dict(ckpt[\"model\"], strict=True)\n",
        "    print(f\"Checkpoint carregado (época {ckpt.get('epoch','?')})\")\n",
        "else:\n",
        "    # Assume que o modelo já está carregado na memória\n",
        "    model = model.to(device)\n",
        "    print(\"Modelo existente utilizado\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# --------------------------\n",
        "# Escrever CSV(s)\n",
        "# --------------------------\n",
        "skipped_shape = 0\n",
        "# Contador de pares de imagens pulados por terem shapes diferentes.\n",
        "# Cria os diretórios de saída se não existirem.\n",
        "Path(os.path.dirname(csv_path) or \".\").mkdir(parents=True, exist_ok=True)\n",
        "if save_probs_csv:\n",
        "    Path(os.path.dirname(probs_csv_path) or \".\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with ExitStack() as stack:\n",
        "    fbin = stack.enter_context(open(csv_path, \"w\", newline=\"\"))\n",
        "    writer_bin = csv.writer(fbin)\n",
        "    writer_bin.writerow(header)\n",
        "# Se a flag for True, abre e prepara o arquivo CSV para as probabilidades\n",
        "    if save_probs_csv:\n",
        "        fprb = stack.enter_context(open(probs_csv_path, \"w\", newline=\"\"))\n",
        "        writer_prb = csv.writer(fprb)\n",
        "        writer_prb.writerow(header)\n",
        "    else:\n",
        "        writer_prb = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, id_ in enumerate(common_ids, 1):\n",
        "            p1, p2 = t1_map[id_], t2_map[id_]\n",
        "\n",
        "            # Leitura + normalização (igual ao treino)\n",
        "            t1 = read_image_minmax(p1).unsqueeze(0).to(device)  # [1,C,H,W]\n",
        "            t2 = read_image_minmax(p2).unsqueeze(0).to(device)  # [1,C,H,W]\n",
        "\n",
        "            # Verificar shapes\n",
        "            if t1.shape != t2.shape:\n",
        "                print(f\"Shape diferente em {id_}: T1 {tuple(t1.shape)} vs T2 {tuple(t2.shape)}. Pulando.\")\n",
        "                skipped_shape += 1\n",
        "                continue\n",
        "\n",
        "            # Inferência\n",
        "            # passa o par de imagens pelo modelo\n",
        "            logits = model(t1, t2)              # [1,1,h,w]\n",
        "            probs  = torch.sigmoid(logits)[0,0] # [h,w]\n",
        "\n",
        "            # Garantir tamanho (H,W) para casar com header\n",
        "            if probs.shape[-2:] != (H, W):\n",
        "                probs = F.interpolate(\n",
        "                    probs.unsqueeze(0).unsqueeze(0),\n",
        "                    size=(H, W),\n",
        "                    mode=\"bilinear\",\n",
        "                    align_corners=False\n",
        "                )[0,0]\n",
        "\n",
        "            # CORREÇÃO: Mantém o nome original com underline e adiciona extensão .tif\n",
        "            id_col = f\"{id_}.tif\"\n",
        "\n",
        "            # Binária\n",
        "            pred_mask = (probs > THRESH).to(torch.uint8).cpu().numpy().reshape(-1)\n",
        "            writer_bin.writerow([id_col] + pred_mask.tolist())\n",
        "\n",
        "            # (Opcional) Probabilidades\n",
        "            if writer_prb is not None:\n",
        "                writer_prb.writerow([id_col] + probs.cpu().numpy().astype(np.float32).reshape(-1).tolist())\n",
        "            # Imprime o progresso a cada 25 imagens.\n",
        "            if i % 25 == 0:\n",
        "                print(f\"Progresso: {i}/{len(common_ids)} pares...\")\n",
        "\n",
        "print(f\"CSV binário salvo em: {csv_path}\")\n",
        "if save_probs_csv:\n",
        "    print(f\"CSV de probabilidades salvo em: {probs_csv_path}\")\n",
        "if skipped_shape:\n",
        "    print(f\"ℹ Pares pulados por shape inconsistente: {skipped_shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H1cllkdl2Dp"
      },
      "source": [
        "# Padronizar o csv ao padrão Kaggle e mostrar primeiras linhas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "vl_wRUK_Chun",
        "outputId": "3d7a9901-7544-4b2b-dd49-fb9f072da02b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Máscaras – shape: (315, 16385)\n",
            "(mostrando apenas as 20 primeiras colunas de pixels)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4c23cedb-554b-4574-a7fd-6bef430bab01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>pixel_0</th>\n",
              "      <th>pixel_1</th>\n",
              "      <th>pixel_2</th>\n",
              "      <th>pixel_3</th>\n",
              "      <th>pixel_4</th>\n",
              "      <th>pixel_5</th>\n",
              "      <th>pixel_6</th>\n",
              "      <th>pixel_7</th>\n",
              "      <th>pixel_8</th>\n",
              "      <th>pixel_9</th>\n",
              "      <th>pixel_10</th>\n",
              "      <th>pixel_11</th>\n",
              "      <th>pixel_12</th>\n",
              "      <th>pixel_13</th>\n",
              "      <th>pixel_14</th>\n",
              "      <th>pixel_15</th>\n",
              "      <th>pixel_16</th>\n",
              "      <th>pixel_17</th>\n",
              "      <th>pixel_18</th>\n",
              "      <th>pixel_19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>recorte_1.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>recorte_2.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>recorte_3.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>recorte_4.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recorte_5.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>recorte_6.tif</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>recorte_7.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>recorte_8.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>recorte_9.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>recorte_10.tif</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c23cedb-554b-4574-a7fd-6bef430bab01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c23cedb-554b-4574-a7fd-6bef430bab01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c23cedb-554b-4574-a7fd-6bef430bab01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2d43e3ef-8f00-4707-958b-a6bf78a6e052\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d43e3ef-8f00-4707-958b-a6bf78a6e052')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2d43e3ef-8f00-4707-958b-a6bf78a6e052 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               id  pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  \\\n",
              "0   recorte_1.tif        0        0        0        0        0        0   \n",
              "1   recorte_2.tif        0        0        0        0        0        0   \n",
              "2   recorte_3.tif        0        0        0        0        0        0   \n",
              "3   recorte_4.tif        0        0        0        0        0        0   \n",
              "4   recorte_5.tif        0        0        0        0        0        0   \n",
              "5   recorte_6.tif        1        1        1        1        1        1   \n",
              "6   recorte_7.tif        0        0        0        0        0        0   \n",
              "7   recorte_8.tif        0        0        0        0        0        0   \n",
              "8   recorte_9.tif        0        0        0        0        0        0   \n",
              "9  recorte_10.tif        0        0        0        0        0        0   \n",
              "\n",
              "   pixel_6  pixel_7  pixel_8  pixel_9  pixel_10  pixel_11  pixel_12  pixel_13  \\\n",
              "0        0        0        0        0         0         0         0         0   \n",
              "1        0        0        0        0         0         0         0         0   \n",
              "2        0        0        0        0         0         0         0         0   \n",
              "3        0        0        0        0         0         0         0         0   \n",
              "4        0        0        0        0         0         0         0         0   \n",
              "5        1        0        0        0         0         0         0         0   \n",
              "6        0        0        0        0         0         0         0         0   \n",
              "7        0        0        0        0         0         0         0         0   \n",
              "8        0        0        0        0         0         0         0         0   \n",
              "9        0        0        0        0         0         0         0         0   \n",
              "\n",
              "   pixel_14  pixel_15  pixel_16  pixel_17  pixel_18  pixel_19  \n",
              "0         0         0         0         0         0         0  \n",
              "1         0         0         0         0         0         0  \n",
              "2         0         0         0         0         0         0  \n",
              "3         0         0         0         0         0         0  \n",
              "4         0         0         0         0         0         0  \n",
              "5         0         0         0         0         0         0  \n",
              "6         0         1         1         1         0         0  \n",
              "7         0         0         0         0         0         0  \n",
              "8         0         0         0         0         0         0  \n",
              "9         0         0         0         0         0         0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV (máscaras) com IDs padronizados salvo em: Siamunet_attentionscSE_norm_ids.csv\n",
            "ℹ CSV de probabilidades não encontrado (opcional): predicted_change_probs.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# >>> ajuste o(s) caminho(s) se necessário <<<\n",
        "csv_masks = \"Siamunet_attentionscSE.csv\"  # CSV de máscaras binárias 0/1\n",
        "csv_probs = \"predicted_change_probs.csv\"    # (opcional) CSV de probabilidades\n",
        "\n",
        "# opções de visualização (só pra ficar legível)\n",
        "pd.set_option(\"display.max_rows\", 20)\n",
        "pd.set_option(\"display.max_columns\", 30)  # aumente se quiser ver mais colunas\n",
        "pd.set_option(\"display.width\", 0)\n",
        "\n",
        "# helper p/ exibir em notebook ou terminal\n",
        "try:\n",
        "    from IPython.display import display\n",
        "except Exception:\n",
        "    display = print\n",
        "\n",
        "def padronizar_id_recorte(x: str) -> str:\n",
        "    \"\"\"\n",
        "    Retorna 'recorte_123.tif' a partir de qualquer variação:\n",
        "      - 'recorte_123.tif'\n",
        "      - 'recorte123.tif'\n",
        "      - 'recorte_123.tiff'\n",
        "      - caminho completo '/.../recorte_123.tif'\n",
        "      - apenas '123' (como fallback) -> 'recorte_123.tif'\n",
        "    \"\"\"\n",
        "    base = os.path.basename(str(x))\n",
        "    root, _ext = os.path.splitext(base)\n",
        "\n",
        "    # Se vier só o número (ex.: \"6\"), vira \"recorte_6\"\n",
        "    if re.fullmatch(r\"\\d+\", root):\n",
        "        root = f\"recorte_{root}\"\n",
        "\n",
        "    # Inserir \"_\" se vier \"recorte123\"\n",
        "    root = re.sub(r\"^(recorte)(\\d+)$\", r\"\\1_\\2\", root, flags=re.IGNORECASE)\n",
        "    # Se já vier \"recorte_123\", mantém\n",
        "    root = re.sub(r\"^(recorte)_(\\d+)$\", r\"\\1_\\2\", root, flags=re.IGNORECASE)\n",
        "\n",
        "    # Normaliza extensão para .tif\n",
        "    return f\"{root}.tif\"\n",
        "\n",
        "def ajustar_id_col(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Aplica a padronização na coluna 'id', se existir.\"\"\"\n",
        "    if \"id\" in df.columns:\n",
        "        df = df.copy()\n",
        "        df[\"id\"] = df[\"id\"].apply(padronizar_id_recorte)\n",
        "    return df\n",
        "\n",
        "# --- máscaras binárias ---\n",
        "if os.path.exists(csv_masks):\n",
        "    dfm = pd.read_csv(csv_masks)\n",
        "    dfm = ajustar_id_col(dfm)\n",
        "    print(f\"Máscaras – shape: {dfm.shape}\")\n",
        "    pixel_cols = [c for c in dfm.columns if str(c).startswith(\"pixel_\")]\n",
        "\n",
        "    # Exibição compacta\n",
        "    if len(pixel_cols) > 20:\n",
        "        cols_view = [\"id\"] + pixel_cols[:20]\n",
        "        print(\"(mostrando apenas as 20 primeiras colunas de pixels)\")\n",
        "        display(dfm[cols_view].head(10))\n",
        "    else:\n",
        "        display(dfm.head(10))\n",
        "\n",
        "    # (Opcional) salvar uma cópia já padronizada\n",
        "    out_masks_norm = os.path.splitext(csv_masks)[0] + \"_norm_ids.csv\"\n",
        "    dfm.to_csv(out_masks_norm, index=False)\n",
        "    print(f\"CSV (máscaras) com IDs padronizados salvo em: {out_masks_norm}\")\n",
        "else:\n",
        "    print(f\"CSV de máscaras não encontrado em: {csv_masks}\")\n",
        "\n",
        "# --- probabilidades (opcional) ---\n",
        "if os.path.exists(csv_probs):\n",
        "    dfp = pd.read_csv(csv_probs)\n",
        "    dfp = ajustar_id_col(dfp)\n",
        "    print(f\"\\nProbabilidades – shape: {dfp.shape}\")\n",
        "    pixel_cols = [c for c in dfp.columns if str(c).startswith(\"pixel_\")]\n",
        "\n",
        "    if len(pixel_cols) > 20:\n",
        "        cols_view = [\"id\"] + pixel_cols[:20]\n",
        "        print(\"(mostrando apenas as 20 primeiras colunas de pixels)\")\n",
        "        display(dfp[cols_view].head(10))\n",
        "    else:\n",
        "        display(dfp.head(10))\n",
        "\n",
        "    # (Opcional) salvar uma cópia já padronizada\n",
        "    out_probs_norm = os.path.splitext(csv_probs)[0] + \"_norm_ids.csv\"\n",
        "    dfp.to_csv(out_probs_norm, index=False)\n",
        "    print(f\"CSV (probabilidades) com IDs padronizados salvo em: {out_probs_norm}\")\n",
        "else:\n",
        "    print(f\"ℹ CSV de probabilidades não encontrado (opcional): {csv_probs}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sTLiSe6BTiYa"
      },
      "outputs": [],
      "source": [
        "# 1) Verifique o tamanho (opcional)\n",
        "!du -sh /content/preds_siamunet/figs\n",
        "\n",
        "# 2) Compacte em ZIP\n",
        "!zip -r -q /content/preds_siamunet/figs.zip /content/preds_siamunet/figs\n",
        "\n",
        "# 3) Baixe para o seu computador\n",
        "from google.colab import files\n",
        "files.download('/content/preds_siamunet/figs')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRU6dfKT6gsb"
      },
      "source": [
        "##Bibliografia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aczte7Dk6h1K"
      },
      "source": [
        "[1] NGOC, Hoang; NGUYEN VINH, Nghi; LÊ, Nhi; NGUYEN, Nam; LE, Thu; DINH NGUYEN, Vinh. Enhancing Semantic Scene Segmentation for Indoor Autonomous Systems Using Advanced Attention-Supported Improved UNet. 2024. DOI: https://doi.org/10.21203/rs.3.rs-4587262/v1.\n",
        "\n",
        "[2] CHICCHON, Miguel; BEDON, Hector; DEL-BLANCO, Carlos; SIPIRAN, Ivan. Semantic Segmentation of Fish and Underwater Environments Using Deep Convolutional Neural Networks and Learned Active Contours. IEEE Access, v. PP, p. 1-1, 2023. DOI: https://doi.org/10.1109/ACCESS.2023.3262649.\n",
        "\n",
        "[3] VERMA, Sagar; GUPTA, Kavya. Post Wildfire Burnt-up Detection using Siamese UNet. In: EUROPEAN CONFERENCE ON MACHINE LEARNING AND PRINCIPLES AND PRACTICE OF KNOWLEDGE DISCOVERY IN DATABASES (ECML PKDD), 2023, Turin. Anais... Turin: [s.n.], set. 2023. Disponível em: https://hal.science/hal-04225474.\n",
        "\n",
        "[4] ZHANG, Xiangrong; HE, Ling; QIN, Kai; DANG, Qi; SI, Hongjie; TANG, Xu; JIAO, Licheng. SMD-Net: Siamese Multi-Scale Difference-Enhancement Network for Change Detection in Remote Sensing. Remote Sensing, v.14, n.7: 1580. 2022. DOI: https://doi.org/10.3390/rs14071580."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}